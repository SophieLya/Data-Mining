# -*- coding: utf-8 -*-
"""Praktek.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1idDLLqMlNUS3vzR_dQ2moaBLfSWencta

# Data Collection
"""

#Define Library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#Read Data
df = pd.read_csv('/content/data.csv')

"""# Data Preparation"""

#Head and Tail Data
df.head()

df.tail()

#Total Number of Rows and Columns
df.shape

#Columns Name
df.columns

#Checking the types of data
df.dtypes

#Dropping irrelevant columns
df = df.drop(['Engine Fuel Type', 'Market Category', 'Vehicle Style', 'Popularity', 'Number of Doors', 'Vehicle Size'], axis=1)
df.head(5)

#Renaming The Columns
df = df.rename(columns={"Engine HP": "HP", "Engine Cylinders": "Cylinders", "Transmission Type": "Transmission", "Driven_Wheels": "Drive Mode","highway MPG": "MPG-H", "city mpg": "MPG-C", "MSRP": "Price" })
df.head(5)

"""# Data Cleaning

"""

#Dropping the duplicate rows
duplicate_rows_df = df[df.duplicated()]
print("number of duplicate rows: ", duplicate_rows_df.shape)

df = df.drop_duplicates()
df.head(5)

df.shape

#Dropping the missing values
print(df.isnull().sum()) #memriksa missing values

df = df.dropna()    # Dropping the missing values.
df.count()

print(df.isnull().sum())

"""# EDA"""

#measures of tendency dan measures of spread data
df.describe()

#Histogram
df.Make.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))
plt.title("Number of cars by make")
plt.ylabel('Number of cars')
plt.xlabel('Make');